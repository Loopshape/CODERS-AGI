import { CodeReviewReport, ChatMessage, MessageSender, LogType } from '../types';

// NOTE: All functions in this file are simulated and do not make real API calls.
// This is to prevent network errors in a browser-based environment and to
// align with the simulation-first nature of the application.

export const getLocalAiSuggestions = async (fileContent: string, environmentInfo: string): Promise<string> => {
    // Simulate a delay as if we're calling a local model
    await new Promise(resolve => setTimeout(resolve, 2500));
    
    const suggestion = `
<!-- Enhanced by Local AI -->
<!-- Environment Context: The user is in '${environmentInfo.split('\n')[2]?.split('=')[1] || 'an unknown directory'}' -->
<div class="container-ai" style="border: 1px solid #388BFD; padding: 1em; margin: 1em; background-color: #161B22;">
    <h1 style="color: #58A6FF;">AI Enhanced Content</h1>
    <p>The following content has been analyzed and restructured by the Local AI model for improved clarity and structure.</p>
    <pre style="background-color: #0D1117; padding: 1em; border-radius: 5px; color: #C9D1D9; white-space: pre-wrap;">${fileContent.replace(/</g, "&lt;").replace(/>/g, "&gt;")}</pre>
</div>
`;
    return suggestion;
};

export const getLocalAiCodeReview = async (codeContent: string): Promise<CodeReviewReport> => {
    // Simulate a delay as if we're calling a local model
    await new Promise(resolve => setTimeout(resolve, 3500));

    const mockReport: CodeReviewReport = {
        reviewSummary: "The code is generally functional, but could benefit from improved semantics and error handling based on local AI analysis.",
        potentialBugs: [
            {
                line: (codeContent.split('\n').findIndex(line => line.includes('document.getElementById')) + 1) || undefined,
                description: "Potential null reference if element does not exist at runtime.",
                suggestion: "Add a null check after `document.getElementById(...)` before accessing its properties to prevent runtime errors."
            }
        ],
        securityVulnerabilities: [],
        performanceImprovements: [
            {
                line: (codeContent.split('\n').findIndex(line => line.includes('addEventListener')) + 1) || undefined,
                description: "Repeatedly adding event listeners in a loop or function call can lead to memory leaks if not managed.",
                suggestion: "Consider using event delegation on a parent element, or ensure listeners are explicitly removed when the component unmounts."
            }
        ]
    };

    // If findIndex returns -1, the line becomes 0. We correct this to undefined.
    if (mockReport.potentialBugs[0]?.line === 0) mockReport.potentialBugs[0].line = undefined;
    if (mockReport.performanceImprovements[0]?.line === 0) mockReport.performanceImprovements[0].line = undefined;
    
    return mockReport;
};

export const chatWithLocalAi = async (messages: ChatMessage[]): Promise<string> => {
    // Simulate a delay as if we're calling a local model
    await new Promise(resolve => setTimeout(resolve, 1200));

    const lastUserMessage = messages.filter(m => m.sender === MessageSender.User).pop();
    const userText = lastUserMessage?.text.toLowerCase() || "";
    
    if (userText.includes("hello") || userText.includes("hi")) {
        return "Hello! I am the local AI assistant. How can I help you today?";
    }
    if (userText.includes("help")) {
        return "I can answer questions about your code, suggest improvements, or help you understand concepts. What's on your mind?";
    }
    if (userText.includes("thank")) {
        return "You're welcome! Let me know if you need anything else.";
    }
     if (userText.includes("error")) {
        return "It seems you're having an issue. Could you describe the error in more detail? I'll do my best to help you troubleshoot it based on common patterns.";
    }

    return "I have processed your request. As a simulated local AI, I've noted your query and will respond with a generic but helpful-sounding answer. What else can I assist you with?";
};


export const getLocalAiBashExtension = async (): Promise<{ output: string; logs: { type: LogType; message:string }[]; fileName: string }> => {
    // Simulate a delay as if we're calling a local model
    await new Promise(resolve => setTimeout(resolve, 1500));

    const mockScriptContent = `
# Generated by Local AI: Advanced Find & Grep
# Searches for a pattern in files matching a name pattern.
function findgrep() {
    if [ "$#" -ne 2 ]; then
        echo "Usage: findgrep <file-pattern> <search-pattern>"
        echo "Example: findgrep \\"*.js\\" \\"console.log\\""
        return 1
    fi
    
    local file_pattern="$1"
    local search_pattern="$2"
    
    echo "Searching for '\${search_pattern}' in files matching '\${file_pattern}'..."
    find . -type f -name "\${file_pattern}" -print0 | xargs -0 grep --color=auto -n "\${search_pattern}"
}`;

    return {
        output: mockScriptContent.trim(),
        logs: [
            { type: LogType.Info, message: "Prompting local AI for a new bash extension..." },
            { type: LogType.Success, message: "Successfully generated bash extension from local AI." }
        ],
        fileName: 'ai_extension.sh'
    };
};
